{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a85a40",
   "metadata": {},
   "source": [
    "# National Wetlands Inventory\n",
    "\n",
    "[![image](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/opengeos/source-coop-readme/blob/main/nwi/README.ipynb)\n",
    "\n",
    "## Description\n",
    "\n",
    "This dataset is a copy of the [National Wetlands Inventory](https://www.fws.gov/program/national-wetlands-inventory), offering the data in more GIS-friendly and [cloud-native geospatial](https://cloudnativegeo.org) formats. The original dataset is distributed as zipped Geodatabase files, and is available for download from [here](https://www.fws.gov/program/national-wetlands-inventory/download-state-wetlands-data).\n",
    "\n",
    "## Data download\n",
    "\n",
    "The script below was used to download the data from the National Wetlands Inventory in Geodatabase format from [here](https://www.fws.gov/program/national-wetlands-inventory/download-state-wetlands-data). The script uses the [leafmap](https://leafmap.org) Python package.\n",
    "\n",
    "First, create a conda environment with the required packages:\n",
    "\n",
    "```bash\n",
    "conda create -n gdal python=3.11\n",
    "conda activate gdal\n",
    "conda install -c conda-forge mamba\n",
    "mamba install -c conda-forge libgdal-arrow-parquet gdal leafmap\n",
    "```\n",
    "\n",
    "If you are using Google Colab, you can install the packages as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db82c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install leafmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc4e202",
   "metadata": {},
   "source": [
    "Then, run the script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leafmap\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://open.gishub.org/data/us/us_states.csv'\n",
    "df = pd.read_csv(url)\n",
    "ids = df['id'].tolist()\n",
    "ids.sort()\n",
    "urls = [f\"https://documentst.ecosphere.fws.gov/wetlands/data/State-Downloads/{id}_geodatabase_wetlands.zip\" for id in ids]\n",
    "leafmap.download_files(urls, out_dir='.', unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0792ed0",
   "metadata": {},
   "source": [
    "## Data conversion\n",
    "\n",
    "The script below was used to convert the data from the original Geodatabase format to [Parquet](https://parquet.apache.org) format. The script uses the [leafmap](https://leafmap.org) Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leafmap\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://open.gishub.org/data/us/us_states.csv'\n",
    "df = pd.read_csv(url)\n",
    "ids = df['id'].tolist()\n",
    "\n",
    "for index, state in enumerate(ids):\n",
    "    print(f'Processing {state} ({index+1}/{len(ids)})')\n",
    "    gdb = f\"{state}_geodatabase_wetlands.gdb/\"\n",
    "    layer_name = f'{state}_Wetlands'\n",
    "    leafmap.gdb_to_vector(gdb, \".\", gdal_driver=\"Parquet\", layers=[layer_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61580651",
   "metadata": {},
   "source": [
    "The total file size of the Geodatabase files is 32.5 GB. The total file size of the Parquet files is 75.8 GB.\n",
    "\n",
    "## Data access\n",
    "\n",
    "The script below can be used to access the data using [DuckDB](https://duckdb.org). The script uses the [duckdb](https://duckdb.org) Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1eeddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "con = duckdb.connect()\n",
    "con.install_extension(\"spatial\")\n",
    "con.load_extension(\"spatial\")\n",
    "\n",
    "state = \"DC\"    # Change to the US State of your choice\n",
    "url = f\"https://data.source.coop/giswqs/nwi/wetlands/{state}_Wetlands.parquet\"\n",
    "con.sql(f\"SELECT * EXCLUDE geometry, ST_GeomFromWKB(geometry) FROM '{url}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2e4909",
   "metadata": {},
   "source": [
    "Alternatively, you can use the aws cli to access the data directly from the S3 bucket:\n",
    "\n",
    "```bash\n",
    "aws s3 ls s3://us-west-2.opendata.source.coop/giswqs/nwi/wetlands/\n",
    "```\n",
    "\n",
    "## Data visualization\n",
    "\n",
    "To visualize the data, you can use the [leafmap](https://leafmap.org) Python package with the [lonboard](https://github.com/developmentseed/lonboard) backend. The script below shows how to install the lonboard backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e6e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "% pip install lonboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015cf9a4",
   "metadata": {},
   "source": [
    "After installing the lonboard backend, you can use the script below to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c3498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leafmap\n",
    "\n",
    "state = \"DC\"   # Change to the US State of your choice\n",
    "url = f\"https://data.source.coop/giswqs/nwi/wetlands/{state}_Wetlands.parquet\"\n",
    "gdf = leafmap.read_parquet(url, return_type='gdf', src_crs='EPSG:5070', dst_crs='EPSG:4326')\n",
    "leafmap.view_vector(gdf, get_fill_color=[0, 0, 255, 128])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da999013",
   "metadata": {},
   "source": [
    "![vector](https://i.imgur.com/HRtpiVd.png)\n",
    "\n",
    "Alternatively, you can specify a color map to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c89bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map =  {\n",
    "        \"Freshwater Forested/Shrub Wetland\": (0, 136, 55),\n",
    "        \"Freshwater Emergent Wetland\": (127, 195, 28),\n",
    "        \"Freshwater Pond\": (104, 140, 192),\n",
    "        \"Estuarine and Marine Wetland\": (102, 194, 165),\n",
    "        \"Riverine\": (1, 144, 191),\n",
    "        \"Lake\": (19, 0, 124),\n",
    "        \"Estuarine and Marine Deepwater\": (0, 124, 136),\n",
    "        \"Other\": (178, 134, 86),\n",
    "    }\n",
    "leafmap.view_vector(gdf, color_column='WETLAND_TYPE', color_map=color_map, opacity=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4169303",
   "metadata": {},
   "source": [
    "![vector-color](https://i.imgur.com/Ejh8hK6.png)\n",
    "\n",
    "Display a legend for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a21a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "leafmap.Legend(title=\"Wetland Type\", legend_dict=color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7242db9",
   "metadata": {},
   "source": [
    "![legend](https://i.imgur.com/fxzHHFN.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
